# -*- coding: utf-8 -*-
"""SpamFilterFinal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pT7fO_v95GuUh2LPclQteTjquvoJDCI5
"""

#First stage is to import libraries for the project 
import numpy as np
import pandas as pd 
import string 
import nltk #Importing Natural Language Toolkit 
from nltk.corpus import stopwords #Importing stopwords from data sets within nltk corpus 
from nltk import punkt

#Next stage involves connecting to my google drive 
from google.colab import drive
drive.mount('/content/drive')

#Creating variable for the data set 
file_data = '/content/drive/My Drive/Colab Notebooks/SpamFolder/SMSSpamCollection.txt'

#Reading the csv file and also sorting out the headers 
data = pd.read_csv(file_data, sep='\t', header=None, names=["Label", "Email"] ) #Header used to remove first row as the header hence setting to none 
data.head()

#Printing the first 5 stop words and the whole punctuation string and verifying it is correct
nltk.download('stopwords')

stopwords = nltk.corpus.stopwords.words('english')
punctuation = string.punctuation



print(stopwords[:5])
print(punctuation)

#Pre-process 

import nltk
nltk.download('punkt')

def pre_process(email): 
  convlowercase = "".join([char.lower() for char in email if char not in punctuation]) #Converting all characters to lowercase 
  tokenize = nltk.tokenize.word_tokenize(convlowercase) #Tokenize used to help with splitting the text into individual words/tokens 
  delete_stopwords = [word for word in tokenize if word not in stopwords] #Deleting the stopwords
  return delete_stopwords
  

data['Processed'] = data['Email'].apply(lambda x: pre_process(x)) #Used to print out results 
data.head()

def categorize_words(): 
  #Creating two empty lists 
  junk_words = []
  not_junkwords = []
  #Filling the first list with spam messages
  for email in data['Processed'][data['Label'] == 'spam']: #Only looping through spam messages
    for word in email: 
      junk_words.append(word)
  #Filling the second list/variable with ham messages 
  for email in data['Processed'][data['Label'] == 'ham']: #Only looping through ham messages
    for word in email: 
      not_junkwords.append(word)
  return junk_words, not_junkwords

junk_words, not_junkwords = categorize_words()

print(junk_words[:5]) 
print(not_junkwords[:5])

#This stage uses a predict function to detect whether the Email is junk or not junk

def predict(email): 
  junk_counter = 0
  nonjunk_counter = 0

  for word in email: 
    junk_counter += junk_words.count(word)
    nonjunk_counter += not_junkwords.count(word)
    print('************* These are the Results *************')

  if nonjunk_counter > junk_counter:
    accuracy = round((nonjunk_counter / (nonjunk_counter + junk_counter) * 100 ))
    print('This message is not junk, this is predicted with {}% certainty'.format(accuracy))

  elif nonjunk_counter == junk_counter: 
    print('This message could possibly be junk')

  else:
    accuracy = round((junk_counter / (nonjunk_counter + junk_counter) * 100 ))
    print('This message is junk, this is predicted with {}% certainty'.format(accuracy))

user_input = input("Please type a spam or ham message to check if our function predicts accurately\n")
#pre-processing the input before prediction
processed_input = pre_process(user_input)

predict(processed_input)

